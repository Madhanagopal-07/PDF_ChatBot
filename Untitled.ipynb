{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f30ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madha\\AppData\\Roaming\\Python\\Python311\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n",
      "C:\\Users\\madha\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'cached_download' (from 'huggingface_hub.file_download') is deprecated and will be removed from version '0.26'. Use `hf_hub_download` instead.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a20dda88d94d0b8fd1bf11e34b0a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c263a729d5643b79f16bb4211769859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03364864b0b4c25b00e755fbb84a845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9605143cd0439b9e1465008eb7ffa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dcee15a65374a9f8f2d3a6418db8841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/66.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0ab7f873cc41d28f121161712e5dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ca8140684649d4ae4000c5b9d5f9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce043c8af27f40588edfb5c4f932eb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657a9690cf634f4885b72ba29484bebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a6264393ea4875b0e1bab24e8bee95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e834ed1272b49b29a2d3dd2d533f0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9274bc4e6c41e2a05b72a90d47477f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40803ea20ae4d60b66827d531a30d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6752d683a824e86812eaeca392545df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madha\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentence_transformers\\models\\Dense.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(input_path, 'pytorch_model.bin'), map_location=torch.device('cpu')))\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceInstructEmbeddings(\n",
    "    model_name=\"hkunlp/instructor-large\",  # or any other valid model name\n",
    "    query_instruction=\"Represent the query for retrieval: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1146d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f9cf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence-transformers==2.2.2\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ---------------------------------------- 0.0/86.0 kB ? eta -:--:--\n",
      "     ---------------------------- ----------- 61.4/86.0 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 86.0/86.0 kB 970.7 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\madha\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers==2.2.2) (4.45.2)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\anaconda\\lib\\site-packages (from sentence-transformers==2.2.2) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\madha\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers==2.2.2) (2.4.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\madha\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers==2.2.2) (0.19.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\madha\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\program files\\anaconda\\lib\\site-packages (from sentence-transformers==2.2.2) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\program files\\anaconda\\lib\\site-packages (from sentence-transformers==2.2.2) (1.10.1)\n",
      "Requirement already satisfied: nltk in c:\\program files\\anaconda\\lib\\site-packages (from sentence-transformers==2.2.2) (3.7)\n",
      "Collecting sentencepiece (from sentence-transformers==2.2.2)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\madha\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers==2.2.2) (0.25.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\madha\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.13.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\madha\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\madha\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\program files\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0)\n",
      "Requirement already satisfied: requests in c:\\program files\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.29.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\madha\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\program files\\anaconda\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\program files\\anaconda\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\program files\\anaconda\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\program files\\anaconda\\lib\\site-packages (from tqdm->sentence-transformers==2.2.2) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\program files\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2022.7.9)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\madha\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\madha\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.20.0)\n",
      "Requirement already satisfied: click in c:\\program files\\anaconda\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\program files\\anaconda\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\anaconda\\lib\\site-packages (from scikit-learn->sentence-transformers==2.2.2) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\program files\\anaconda\\lib\\site-packages (from torchvision->sentence-transformers==2.2.2) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\anaconda\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\program files\\anaconda\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.2.1)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 143.4/991.5 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 256.0/991.5 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 419.8/991.5 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 563.2/991.5 kB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 747.5/991.5 kB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 952.3/991.5 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 991.5/991.5 kB 3.5 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125960 sha256=23bb5cfec0ea3587f41da33d9f2ecb1bce354e86bf8bf7c8c73c5262124ba3ff\n",
      "  Stored in directory: c:\\users\\madha\\appdata\\local\\pip\\cache\\wheels\\ff\\27\\bf\\ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 3.2.0\n",
      "    Uninstalling sentence-transformers-3.2.0:\n",
      "      Successfully uninstalled sentence-transformers-3.2.0\n",
      "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-huggingface 0.1.0 requires sentence-transformers>=2.6.0, but you have sentence-transformers 2.2.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a3f61a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Check the url of your file; returned status code 401",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n\u001b[0;32m      3\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://drive.google.com/file/d/1lvF_LEXs-QliNYRAWr8GQsZcCJqx1nfk/view?usp=sharing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m loader \u001b[38;5;241m=\u001b[39m PyPDFLoader(file_path)\n\u001b[0;32m      6\u001b[0m docs \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(docs))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\document_loaders\\pdf.py:241\u001b[0m, in \u001b[0;36mPyPDFLoader.__init__\u001b[1;34m(self, file_path, password, headers, extract_images, extraction_mode, extraction_kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpypdf package not found, please install it with `pip install pypdf`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m     )\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(file_path, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m PyPDFParser(\n\u001b[0;32m    243\u001b[0m     password\u001b[38;5;241m=\u001b[39mpassword,\n\u001b[0;32m    244\u001b[0m     extract_images\u001b[38;5;241m=\u001b[39mextract_images,\n\u001b[0;32m    245\u001b[0m     extraction_mode\u001b[38;5;241m=\u001b[39mextraction_mode,\n\u001b[0;32m    246\u001b[0m     extraction_kwargs\u001b[38;5;241m=\u001b[39mextraction_kwargs,\n\u001b[0;32m    247\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\document_loaders\\pdf.py:108\u001b[0m, in \u001b[0;36mBasePDFLoader.__init__\u001b[1;34m(self, file_path, headers)\u001b[0m\n\u001b[0;32m    106\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck the url of your file; returned status code \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;241m%\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus_code\n\u001b[0;32m    111\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(temp_pdf, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    114\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(r\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[1;31mValueError\u001b[0m: Check the url of your file; returned status code 401"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"https://drive.google.com/file/d/1lvF_LEXs-QliNYRAWr8GQsZcCJqx1nfk/view?usp=sharing\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f281db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pypdf langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78f63bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning                   SrihariTopics•Numerical Computation•Gradient-based Optimization–Stationary points, Local minima–Second Derivative–Convex Optimization–Lagrangian\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6264d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'go.pdf', 'page': 2}\n"
     ]
    }
   ],
   "source": [
    "print(docs[2].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c5aa759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfeb0cd6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 58 0 (offset 0)\n",
      "Ignoring wrong pointing object 60 0 (offset 0)\n",
      "Ignoring wrong pointing object 68 0 (offset 0)\n",
      "Ignoring wrong pointing object 88 0 (offset 0)\n",
      "Ignoring wrong pointing object 92 0 (offset 0)\n",
      "Ignoring wrong pointing object 104 0 (offset 0)\n",
      "Ignoring wrong pointing object 116 0 (offset 0)\n",
      "Ignoring wrong pointing object 119 0 (offset 0)\n",
      "Ignoring wrong pointing object 128 0 (offset 0)\n",
      "Ignoring wrong pointing object 136 0 (offset 0)\n",
      "Ignoring wrong pointing object 141 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 153 0 (offset 0)\n",
      "Ignoring wrong pointing object 157 0 (offset 0)\n",
      "Ignoring wrong pointing object 159 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n",
      "Ignoring wrong pointing object 172 0 (offset 0)\n",
      "Ignoring wrong pointing object 174 0 (offset 0)\n",
      "Ignoring wrong pointing object 182 0 (offset 0)\n",
      "Ignoring wrong pointing object 185 0 (offset 0)\n",
      "Ignoring wrong pointing object 191 0 (offset 0)\n",
      "Ignoring wrong pointing object 193 0 (offset 0)\n",
      "Ignoring wrong pointing object 201 0 (offset 0)\n",
      "Ignoring wrong pointing object 203 0 (offset 0)\n",
      "Ignoring wrong pointing object 206 0 (offset 0)\n",
      "Ignoring wrong pointing object 213 0 (offset 0)\n",
      "Ignoring wrong pointing object 215 0 (offset 0)\n",
      "Ignoring wrong pointing object 223 0 (offset 0)\n",
      "Ignoring wrong pointing object 225 0 (offset 0)\n",
      "Ignoring wrong pointing object 227 0 (offset 0)\n",
      "Ignoring wrong pointing object 232 0 (offset 0)\n",
      "Ignoring wrong pointing object 237 0 (offset 0)\n",
      "Ignoring wrong pointing object 244 0 (offset 0)\n",
      "Ignoring wrong pointing object 246 0 (offset 0)\n",
      "Ignoring wrong pointing object 252 0 (offset 0)\n",
      "Ignoring wrong pointing object 254 0 (offset 0)\n",
      "Ignoring wrong pointing object 258 0 (offset 0)\n",
      "Ignoring wrong pointing object 267 0 (offset 0)\n",
      "Ignoring wrong pointing object 274 0 (offset 0)\n",
      "Ignoring wrong pointing object 282 0 (offset 0)\n",
      "Ignoring wrong pointing object 284 0 (offset 0)\n",
      "Ignoring wrong pointing object 292 0 (offset 0)\n",
      "Ignoring wrong pointing object 295 0 (offset 0)\n",
      "Ignoring wrong pointing object 301 0 (offset 0)\n",
      "Ignoring wrong pointing object 310 0 (offset 0)\n",
      "Ignoring wrong pointing object 313 0 (offset 0)\n",
      "Ignoring wrong pointing object 321 0 (offset 0)\n",
      "Ignoring wrong pointing object 326 0 (offset 0)\n",
      "Ignoring wrong pointing object 334 0 (offset 0)\n",
      "Ignoring wrong pointing object 346 0 (offset 0)\n",
      "Ignoring wrong pointing object 355 0 (offset 0)\n",
      "Ignoring wrong pointing object 363 0 (offset 0)\n",
      "Ignoring wrong pointing object 373 0 (offset 0)\n",
      "Ignoring wrong pointing object 379 0 (offset 0)\n",
      "Ignoring wrong pointing object 381 0 (offset 0)\n",
      "Ignoring wrong pointing object 389 0 (offset 0)\n",
      "Ignoring wrong pointing object 398 0 (offset 0)\n",
      "Ignoring wrong pointing object 400 0 (offset 0)\n",
      "Ignoring wrong pointing object 407 0 (offset 0)\n",
      "Ignoring wrong pointing object 409 0 (offset 0)\n",
      "Ignoring wrong pointing object 417 0 (offset 0)\n",
      "Ignoring wrong pointing object 428 0 (offset 0)\n",
      "Ignoring wrong pointing object 437 0 (offset 0)\n",
      "Ignoring wrong pointing object 455 0 (offset 0)\n",
      "Ignoring wrong pointing object 463 0 (offset 0)\n",
      "Ignoring wrong pointing object 466 0 (offset 0)\n",
      "Ignoring wrong pointing object 475 0 (offset 0)\n",
      "Ignoring wrong pointing object 489 0 (offset 0)\n",
      "Ignoring wrong pointing object 499 0 (offset 0)\n",
      "Ignoring wrong pointing object 506 0 (offset 0)\n",
      "Ignoring wrong pointing object 514 0 (offset 0)\n",
      "Ignoring wrong pointing object 522 0 (offset 0)\n",
      "Ignoring wrong pointing object 530 0 (offset 0)\n",
      "Ignoring wrong pointing object 538 0 (offset 0)\n",
      "Ignoring wrong pointing object 543 0 (offset 0)\n",
      "Ignoring wrong pointing object 551 0 (offset 0)\n",
      "Ignoring wrong pointing object 555 0 (offset 0)\n",
      "Ignoring wrong pointing object 559 0 (offset 0)\n",
      "Ignoring wrong pointing object 565 0 (offset 0)\n",
      "Ignoring wrong pointing object 572 0 (offset 0)\n",
      "Ignoring wrong pointing object 574 0 (offset 0)\n",
      "Ignoring wrong pointing object 581 0 (offset 0)\n",
      "Ignoring wrong pointing object 583 0 (offset 0)\n",
      "Ignoring wrong pointing object 592 0 (offset 0)\n",
      "Ignoring wrong pointing object 601 0 (offset 0)\n",
      "Ignoring wrong pointing object 604 0 (offset 0)\n",
      "Ignoring wrong pointing object 606 0 (offset 0)\n",
      "Ignoring wrong pointing object 612 0 (offset 0)\n",
      "Ignoring wrong pointing object 619 0 (offset 0)\n",
      "Ignoring wrong pointing object 621 0 (offset 0)\n",
      "Ignoring wrong pointing object 631 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "chunks=loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4873f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "vectordb = Chroma.from_documents(chunks,\n",
    "                            embedding=embeddings,\n",
    "                            persist_directory='./vs_db')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d217bd3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63c55a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f03ded0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 29, 'source': 'go.pdf'}, page_content='Deep Learning                   SrihariConvex Optimization•Applicable only to convex functions–functions which are well-behaved, –e.g., lack saddle points and all local minima are global minima•For such functions, Hessian is positive semi-definite everywhere•Many ML optimization problems, particularly deep learning, cannot be expressed as convex optimization30'),\n",
       " Document(metadata={'page': 2, 'source': 'go.pdf'}, page_content='Deep Learning                   SrihariGradient-Based Optimization•Most ML algorithms involve optimization•Minimize/maximize a function f (x)by altering x–Usually stated a minimization–Maximization accomplished by  minimizing –f(x)•f (x)referred to as objective function or criterion–In minimization also referred to as loss function cost, or error–Example is linear least squares–Denote optimum value by x*=argminf (x)3   f(x)=12||Ax−b||2'),\n",
       " Document(metadata={'page': 30, 'source': 'go.pdf'}, page_content='Deep Learning                   SrihariConstrained Optimization•We may wish to optimize f(x)when the solution xis constrained to lie in set S–Such values of xare feasible solutions•Often we want a solution that is small, such as ||x||≤1•Simple approach: modify gradient descent taking constraint into account (using Lagrangianformulation)31'),\n",
       " Document(metadata={'page': 28, 'source': 'go.pdf'}, page_content='Deep Learning                   SrihariSummary of Gradient Methods•First order optimization algorithms: those that use only the gradient•Second order optimization algorithms: use the Hessian matrix such as Newton’s method•Family of functions used in ML is complicated, so optimization is more complex than in other fields–No guarantees•Some guarantees by using Lipschitzcontinuous functions, •with Lipschitzconstant L29     f(x)−f(y)≤Lx-y2')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdocs = retriever.invoke(\"what is optimization\")\n",
    "rdocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a51635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret_key import key\n",
    "SECRET_KEY=key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95c981a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "     temperature=0,\n",
    "    groq_api_key=SECRET_KEY,\n",
    "    model_name=\"llama-3.1-70b-versatile\",\n",
    "    max_tokens=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56963223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template ='''\n",
    "\n",
    "### INSTRUCTION:\n",
    "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
    "### CONTEXT: {context}\n",
    "\n",
    "### QUESTION: {question}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "254bbdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_llm(\n",
    "    llm, retriever=vectordb.as_retriever(), prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74e0a254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Optimization is the process of finding the best solution among a set of possible solutions, typically by minimizing or maximizing a function, often referred to as the objective function or loss function.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke(\"what is optimization\")['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d93184f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know. The provided context is about Deep Learning, specifically discussing topics such as numerical computation, gradient-based optimization, and multidimensional second derivative tests. There is no mention of computer networks.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke(\"what is computer network\")['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "390f0e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The provided context does not explicitly define what deep learning is. It appears to be a series of lecture slides on deep learning, but it does not provide a definition of the term. The context focuses on calculus in optimization, specifically gradient-based optimization, and discusses concepts such as derivatives and gradient descent. However, it does not provide a clear definition of deep learning itself.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke(\"what is deep learning \")['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c48b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
